CMD: python /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py --model_name openai/whisper-medium.en --dataset_part base --train_fraction 0.5 --validation_samples 200 --epochs 1 --language en --task transcribe --per_device_train_batch_size 8 --gradient_accumulation_steps 4 --learning_rate 0.001 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --seed 42 --num_proc 1 --eval_strategy epoch --eval_steps 100 --run_stage coarse --run_id coarse_015 --skip_save --metrics_csv /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_015.csv
Using the latest cached version of the module from /home/pandeys2/.cache/huggingface/modules/datasets_modules/datasets/HF-SaLAI--salai_atc0/6a6a809cccd83aaa7dae50203e4c7f7fc6313a701a3deebe3dfca35a211f125c (last modified on Wed Aug  6 19:14:44 2025) since it couldn't be found locally at HF-SaLAI/salai_atc0, or remotely on the Hugging Face Hub.
/home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py:326: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
Using device: cuda
---- PATH DEBUG ----
CWD:            /home/pandeys2/Workspace/salai
__file__:       /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py
script_dir:     /home/pandeys2/Workspace/salai/asr_finetune
repo_root:      /home/pandeys2/Workspace/salai
finetuned_dir:  /home/pandeys2/Workspace/salai/finetuned_models
OUTPUT DIR:     /home/pandeys2/Workspace/salai/finetuned_models/whisper_lora_whisper-medium.en_base
--------------------
trainable params: 4,718,592 || all params: 768,575,488 || trainable%: 0.6139
  0%|          | 0/107 [00:00<?, ?it/s]/home/pandeys2/Workspace/salai/.venv/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  1%|          | 1/107 [00:04<08:12,  4.64s/it]  2%|▏         | 2/107 [00:08<07:15,  4.15s/it]  3%|▎         | 3/107 [00:12<06:54,  3.98s/it]  4%|▎         | 4/107 [00:16<06:43,  3.91s/it]  5%|▍         | 5/107 [00:19<06:34,  3.87s/it]  6%|▌         | 6/107 [00:23<06:27,  3.84s/it]  7%|▋         | 7/107 [00:27<06:22,  3.82s/it]  7%|▋         | 8/107 [00:31<06:17,  3.81s/it]  8%|▊         | 9/107 [00:34<06:12,  3.80s/it]  9%|▉         | 10/107 [00:38<06:08,  3.80s/it]                                                  9%|▉         | 10/107 [00:38<06:08,  3.80s/it] 10%|█         | 11/107 [00:42<06:04,  3.79s/it] 11%|█         | 12/107 [00:46<06:00,  3.80s/it] 12%|█▏        | 13/107 [00:50<05:56,  3.80s/it] 13%|█▎        | 14/107 [00:53<05:53,  3.80s/it] 14%|█▍        | 15/107 [00:57<05:49,  3.80s/it] 15%|█▍        | 16/107 [01:01<05:45,  3.80s/it] 16%|█▌        | 17/107 [01:05<05:41,  3.79s/it] 17%|█▋        | 18/107 [01:09<05:37,  3.79s/it] 18%|█▊        | 19/107 [01:12<05:33,  3.79s/it] 19%|█▊        | 20/107 [01:16<05:29,  3.79s/it]                                                 19%|█▊        | 20/107 [01:16<05:29,  3.79s/it] 20%|█▉        | 21/107 [01:20<05:26,  3.79s/it] 21%|██        | 22/107 [01:24<05:22,  3.79s/it] 21%|██▏       | 23/107 [01:28<05:18,  3.79s/it] 22%|██▏       | 24/107 [01:31<05:14,  3.79s/it] 23%|██▎       | 25/107 [01:35<05:12,  3.81s/it] 24%|██▍       | 26/107 [01:39<05:08,  3.80s/it] 25%|██▌       | 27/107 [01:43<05:03,  3.80s/it] 26%|██▌       | 28/107 [01:47<04:59,  3.79s/it] 27%|██▋       | 29/107 [01:50<04:55,  3.79s/it] 28%|██▊       | 30/107 [01:54<04:51,  3.78s/it]                                                 28%|██▊       | 30/107 [01:54<04:51,  3.78s/it] 29%|██▉       | 31/107 [01:58<04:47,  3.79s/it] 30%|██▉       | 32/107 [02:02<04:44,  3.79s/it] 31%|███       | 33/107 [02:05<04:40,  3.79s/it] 32%|███▏      | 34/107 [02:09<04:36,  3.78s/it] 33%|███▎      | 35/107 [02:13<04:32,  3.78s/it] 34%|███▎      | 36/107 [02:17<04:28,  3.78s/it] 35%|███▍      | 37/107 [02:21<04:24,  3.78s/it] 36%|███▌      | 38/107 [02:24<04:20,  3.78s/it] 36%|███▋      | 39/107 [02:28<04:16,  3.78s/it] 37%|███▋      | 40/107 [02:32<04:13,  3.78s/it]                                                 37%|███▋      | 40/107 [02:32<04:13,  3.78s/it] 38%|███▊      | 41/107 [02:36<04:09,  3.78s/it] 39%|███▉      | 42/107 [02:39<04:06,  3.78s/it] 40%|████      | 43/107 [02:43<04:02,  3.78s/it] 41%|████      | 44/107 [02:47<03:58,  3.79s/it] 42%|████▏     | 45/107 [02:51<03:54,  3.79s/it] 43%|████▎     | 46/107 [02:55<03:50,  3.78s/it] 44%|████▍     | 47/107 [02:58<03:46,  3.78s/it] 45%|████▍     | 48/107 [03:02<03:43,  3.79s/it] 46%|████▌     | 49/107 [03:06<03:39,  3.78s/it] 47%|████▋     | 50/107 [03:10<03:35,  3.78s/it]                                                 47%|████▋     | 50/107 [03:10<03:35,  3.78s/it] 48%|████▊     | 51/107 [03:14<03:32,  3.80s/it] 49%|████▊     | 52/107 [03:17<03:29,  3.80s/it] 50%|████▉     | 53/107 [03:21<03:24,  3.80s/it] 50%|█████     | 54/107 [03:25<03:20,  3.79s/it] 51%|█████▏    | 55/107 [03:29<03:16,  3.78s/it] 52%|█████▏    | 56/107 [03:33<03:13,  3.79s/it] 53%|█████▎    | 57/107 [03:36<03:09,  3.79s/it] 54%|█████▍    | 58/107 [03:40<03:05,  3.79s/it] 55%|█████▌    | 59/107 [03:44<03:01,  3.79s/it] 56%|█████▌    | 60/107 [03:48<02:57,  3.79s/it]                                                 56%|█████▌    | 60/107 [03:48<02:57,  3.79s/it] 57%|█████▋    | 61/107 [03:51<02:54,  3.79s/it] 58%|█████▊    | 62/107 [03:55<02:50,  3.78s/it] 59%|█████▉    | 63/107 [03:59<02:46,  3.78s/it] 60%|█████▉    | 64/107 [04:03<02:42,  3.78s/it] 61%|██████    | 65/107 [04:07<02:38,  3.77s/it] 62%|██████▏   | 66/107 [04:10<02:34,  3.77s/it] 63%|██████▎   | 67/107 [04:14<02:30,  3.77s/it] 64%|██████▎   | 68/107 [04:18<02:27,  3.77s/it] 64%|██████▍   | 69/107 [04:22<02:23,  3.77s/it] 65%|██████▌   | 70/107 [04:25<02:19,  3.77s/it]                                                 65%|██████▌   | 70/107 [04:25<02:19,  3.77s/it] 66%|██████▋   | 71/107 [04:29<02:15,  3.77s/it] 67%|██████▋   | 72/107 [04:33<02:12,  3.77s/it] 68%|██████▊   | 73/107 [04:37<02:08,  3.77s/it] 69%|██████▉   | 74/107 [04:40<02:04,  3.77s/it] 70%|███████   | 75/107 [04:44<02:00,  3.77s/it] 71%|███████   | 76/107 [04:48<01:56,  3.77s/it] 72%|███████▏  | 77/107 [04:52<01:53,  3.77s/it] 73%|███████▎  | 78/107 [04:56<01:50,  3.80s/it] 74%|███████▍  | 79/107 [04:59<01:46,  3.79s/it] 75%|███████▍  | 80/107 [05:03<01:42,  3.79s/it]                                                 75%|███████▍  | 80/107 [05:03<01:42,  3.79s/it] 76%|███████▌  | 81/107 [05:07<01:38,  3.78s/it] 77%|███████▋  | 82/107 [05:11<01:34,  3.78s/it] 78%|███████▊  | 83/107 [05:15<01:30,  3.78s/it] 79%|███████▊  | 84/107 [05:18<01:26,  3.78s/it] 79%|███████▉  | 85/107 [05:22<01:22,  3.77s/it] 80%|████████  | 86/107 [05:26<01:19,  3.78s/it] 81%|████████▏ | 87/107 [05:30<01:15,  3.78s/it] 82%|████████▏ | 88/107 [05:33<01:11,  3.78s/it] 83%|████████▎ | 89/107 [05:37<01:07,  3.77s/it] 84%|████████▍ | 90/107 [05:41<01:04,  3.77s/it]                                                 84%|████████▍ | 90/107 [05:41<01:04,  3.77s/it] 85%|████████▌ | 91/107 [05:45<01:00,  3.77s/it] 86%|████████▌ | 92/107 [05:49<00:56,  3.78s/it] 87%|████████▋ | 93/107 [05:52<00:52,  3.78s/it] 88%|████████▊ | 94/107 [05:56<00:49,  3.78s/it] 89%|████████▉ | 95/107 [06:00<00:45,  3.78s/it] 90%|████████▉ | 96/107 [06:04<00:41,  3.78s/it] 91%|█████████ | 97/107 [06:07<00:37,  3.78s/it] 92%|█████████▏| 98/107 [06:11<00:33,  3.78s/it] 93%|█████████▎| 99/107 [06:15<00:30,  3.77s/it] 93%|█████████▎| 100/107 [06:19<00:26,  3.77s/it]                                                  93%|█████████▎| 100/107 [06:19<00:26,  3.77s/it] 94%|█████████▍| 101/107 [06:22<00:22,  3.77s/it] 95%|█████████▌| 102/107 [06:26<00:18,  3.77s/it] 96%|█████████▋| 103/107 [06:30<00:15,  3.77s/it] 97%|█████████▋| 104/107 [06:34<00:11,  3.80s/it] 98%|█████████▊| 105/107 [06:38<00:07,  3.80s/it] 99%|█████████▉| 106/107 [06:41<00:03,  3.79s/it]100%|██████████| 107/107 [06:43<00:00,  2.98s/it]Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
{'loss': 2.4444, 'grad_norm': 2.2550723552703857, 'learning_rate': 0.0009158878504672897, 'epoch': 0.09}
{'loss': 1.2308, 'grad_norm': 1.0860670804977417, 'learning_rate': 0.0008317757009345795, 'epoch': 0.19}
{'loss': 0.8569, 'grad_norm': 1.0737336874008179, 'learning_rate': 0.0007383177570093458, 'epoch': 0.28}
{'loss': 1.2112, 'grad_norm': 1.9522486925125122, 'learning_rate': 0.0006542056074766354, 'epoch': 0.38}
{'loss': 0.7491, 'grad_norm': 1.1205052137374878, 'learning_rate': 0.0005607476635514019, 'epoch': 0.47}
{'loss': 0.691, 'grad_norm': 1.0952430963516235, 'learning_rate': 0.00046728971962616824, 'epoch': 0.56}
{'loss': 0.6005, 'grad_norm': 0.7822282910346985, 'learning_rate': 0.00037383177570093456, 'epoch': 0.66}
{'loss': 0.5953, 'grad_norm': 0.9649384021759033, 'learning_rate': 0.00028037383177570094, 'epoch': 0.75}
{'loss': 0.5342, 'grad_norm': 1.0182652473449707, 'learning_rate': 0.00018691588785046728, 'epoch': 0.85}
{'loss': 0.533, 'grad_norm': 1.0232625007629395, 'learning_rate': 9.345794392523364e-05, 'epoch': 0.94}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [02:49<32:29, 84.77s/it][A
 12%|█▏        | 3/25 [05:38<43:59, 119.98s/it][A
 16%|█▌        | 4/25 [08:28<48:29, 138.57s/it][A
 20%|██        | 5/25 [11:18<49:47, 149.39s/it][A
 24%|██▍       | 6/25 [14:08<49:28, 156.26s/it][A
 28%|██▊       | 7/25 [16:58<48:10, 160.57s/it][A
 32%|███▏      | 8/25 [19:47<46:18, 163.45s/it][A
 36%|███▌      | 9/25 [22:37<44:05, 165.36s/it][A
 40%|████      | 10/25 [25:27<41:40, 166.71s/it][A
 44%|████▍     | 11/25 [28:17<39:07, 167.69s/it][A
 48%|████▊     | 12/25 [31:06<36:27, 168.26s/it][A
 52%|█████▏    | 13/25 [33:56<33:43, 168.63s/it][A
 56%|█████▌    | 14/25 [36:45<30:58, 168.92s/it][A
 60%|██████    | 15/25 [39:35<28:11, 169.15s/it][A
 64%|██████▍   | 16/25 [42:25<25:24, 169.38s/it][A
 68%|██████▊   | 17/25 [45:14<22:35, 169.45s/it][A
 72%|███████▏  | 18/25 [48:04<19:46, 169.53s/it][A
 76%|███████▌  | 19/25 [50:54<16:57, 169.60s/it][A
 80%|████████  | 20/25 [53:43<14:07, 169.53s/it][A
 84%|████████▍ | 21/25 [56:33<11:18, 169.61s/it][A
 88%|████████▊ | 22/25 [59:23<08:29, 169.72s/it][A
 92%|█████████▏| 23/25 [1:02:12<05:39, 169.59s/it][A
 96%|█████████▌| 24/25 [1:05:02<02:49, 169.62s/it][A
100%|██████████| 25/25 [1:07:50<00:00, 169.15s/it][A                                                 
                                                  [A100%|██████████| 107/107 [1:19:36<00:00,  2.98s/it]
100%|██████████| 25/25 [1:10:02<00:00, 169.15s/it][A
                                                  [A                                                   100%|██████████| 107/107 [1:19:36<00:00,  2.98s/it]100%|██████████| 107/107 [1:19:36<00:00, 44.64s/it]
{'eval_loss': 0.496773362159729, 'eval_wer': 100.0, 'eval_runtime': 4373.0187, 'eval_samples_per_second': 0.046, 'eval_steps_per_second': 0.006, 'epoch': 1.0}
{'train_runtime': 4776.0572, 'train_samples_per_second': 0.713, 'train_steps_per_second': 0.022, 'train_loss': 0.9135198325754326, 'epoch': 1.0}
Training complete.
Skipping all weight saves (--skip_save).
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [02:49<32:33, 84.93s/it] 12%|█▏        | 3/25 [05:39<44:02, 120.13s/it] 16%|█▌        | 4/25 [08:29<48:31, 138.64s/it] 20%|██        | 5/25 [11:18<49:49, 149.47s/it] 24%|██▍       | 6/25 [14:08<49:28, 156.22s/it] 28%|██▊       | 7/25 [16:58<48:10, 160.60s/it] 32%|███▏      | 8/25 [19:48<46:18, 163.46s/it] 36%|███▌      | 9/25 [22:38<44:07, 165.48s/it] 40%|████      | 10/25 [25:27<41:41, 166.76s/it] 44%|████▍     | 11/25 [28:17<39:08, 167.78s/it] 48%|████▊     | 12/25 [31:07<36:29, 168.42s/it] 52%|█████▏    | 13/25 [33:57<33:46, 168.92s/it] 56%|█████▌    | 14/25 [36:47<31:00, 169.18s/it] 60%|██████    | 15/25 [39:37<28:13, 169.38s/it] 64%|██████▍   | 16/25 [42:27<25:25, 169.53s/it] 68%|██████▊   | 17/25 [45:17<22:37, 169.63s/it] 72%|███████▏  | 18/25 [48:07<19:48, 169.77s/it] 76%|███████▌  | 19/25 [50:57<16:59, 169.89s/it] 80%|████████  | 20/25 [53:47<14:09, 169.81s/it] 84%|████████▍ | 21/25 [56:37<11:19, 169.93s/it] 88%|████████▊ | 22/25 [59:27<08:29, 170.00s/it] 92%|█████████▏| 23/25 [1:02:17<05:39, 169.93s/it] 96%|█████████▌| 24/25 [1:05:06<02:49, 169.87s/it]100%|██████████| 25/25 [1:07:55<00:00, 169.37s/it]100%|██████████| 25/25 [1:10:07<00:00, 168.31s/it]
[sweep] Metrics written to: /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_015.csv
