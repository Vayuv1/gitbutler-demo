CMD: python /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py --model_name openai/whisper-medium.en --dataset_part base --train_fraction 0.25 --validation_samples 200 --epochs 1 --language en --task transcribe --per_device_train_batch_size 8 --gradient_accumulation_steps 4 --learning_rate 0.00075 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --seed 42 --num_proc 1 --eval_strategy epoch --eval_steps 100 --run_stage coarse --run_id coarse_001 --skip_save --metrics_csv /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_001.csv
Using the latest cached version of the module from /home/pandeys2/.cache/huggingface/modules/datasets_modules/datasets/HF-SaLAI--salai_atc0/6a6a809cccd83aaa7dae50203e4c7f7fc6313a701a3deebe3dfca35a211f125c (last modified on Wed Aug  6 19:14:44 2025) since it couldn't be found locally at HF-SaLAI/salai_atc0, or remotely on the Hugging Face Hub.
Using device: cuda
---- PATH DEBUG ----
CWD:            /home/pandeys2/Workspace/salai
__file__:       /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py
script_dir:     /home/pandeys2/Workspace/salai/asr_finetune
repo_root:      /home/pandeys2/Workspace/salai
finetuned_dir:  /home/pandeys2/Workspace/salai/finetuned_models
OUTPUT DIR:     /home/pandeys2/Workspace/salai/finetuned_models/whisper_lora_whisper-medium.en_base
--------------------
Filter:   0%|          | 0/6853 [00:00<?, ? examples/s]/home/pandeys2/Workspace/salai/.venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:503: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.
  warnings.warn(
Filter:  15%|â–ˆâ–        | 1000/6853 [00:00<00:03, 1474.08 examples/s]Filter:  29%|â–ˆâ–ˆâ–‰       | 2000/6853 [00:00<00:02, 2211.21 examples/s]Filter:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3000/6853 [00:01<00:01, 2570.33 examples/s]Filter:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4000/6853 [00:01<00:01, 2793.11 examples/s]Filter:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5000/6853 [00:01<00:00, 3013.65 examples/s]Filter:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 6000/6853 [00:02<00:00, 3207.96 examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6853/6853 [00:02<00:00, 3182.35 examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6853/6853 [00:02<00:00, 2821.71 examples/s]
Filter:   0%|          | 0/200 [00:00<?, ? examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 4371.62 examples/s]
Map:   0%|          | 0/1702 [00:00<?, ? examples/s]Map:   3%|â–Ž         | 47/1702 [00:00<00:03, 452.59 examples/s]Map:   6%|â–Œ         | 98/1702 [00:00<00:03, 479.67 examples/s]Map:   9%|â–‰         | 150/1702 [00:00<00:03, 492.21 examples/s]Map:  13%|â–ˆâ–Ž        | 226/1702 [00:00<00:02, 492.91 examples/s]Map:  17%|â–ˆâ–‹        | 281/1702 [00:00<00:02, 506.23 examples/s]Map:  20%|â–ˆâ–‰        | 334/1702 [00:00<00:02, 510.61 examples/s]Map:  23%|â–ˆâ–ˆâ–Ž       | 387/1702 [00:00<00:02, 513.75 examples/s]Map:  27%|â–ˆâ–ˆâ–‹       | 463/1702 [00:00<00:02, 506.93 examples/s]Map:  30%|â–ˆâ–ˆâ–ˆ       | 514/1702 [00:01<00:02, 504.02 examples/s]Map:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 567/1702 [00:01<00:02, 506.68 examples/s]Map:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 619/1702 [00:01<00:02, 508.02 examples/s]Map:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 672/1702 [00:01<00:02, 512.56 examples/s]Map:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 746/1702 [00:01<00:01, 499.84 examples/s]Map:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 799/1702 [00:01<00:01, 505.48 examples/s]Map:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 852/1702 [00:01<00:01, 507.97 examples/s]Map:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 906/1702 [00:01<00:01, 512.71 examples/s]Map:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 959/1702 [00:01<00:01, 515.47 examples/s]Map:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1027/1702 [00:02<00:04, 153.20 examples/s]Map:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1082/1702 [00:03<00:03, 192.74 examples/s]Map:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1136/1702 [00:03<00:02, 235.63 examples/s]Map:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1192/1702 [00:03<00:01, 283.68 examples/s]Map:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1247/1702 [00:03<00:01, 330.05 examples/s]Map:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1301/1702 [00:03<00:01, 370.88 examples/s]Map:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1357/1702 [00:03<00:00, 411.62 examples/s]Map:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1411/1702 [00:03<00:00, 441.33 examples/s]Map:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1465/1702 [00:03<00:00, 466.17 examples/s]Map:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1519/1702 [00:03<00:00, 482.52 examples/s]Map:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1573/1702 [00:03<00:00, 495.16 examples/s]Map:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1627/1702 [00:04<00:00, 506.93 examples/s]Map:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1681/1702 [00:04<00:00, 515.28 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1702/1702 [00:05<00:00, 334.37 examples/s]
Map:   0%|          | 0/199 [00:00<?, ? examples/s]Map:  27%|â–ˆâ–ˆâ–‹       | 53/199 [00:00<00:00, 522.10 examples/s]Map:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 107/199 [00:00<00:00, 529.46 examples/s]Map:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/199 [00:00<00:00, 533.88 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [00:00<00:00, 344.40 examples/s]
/home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py:326: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
trainable params: 4,718,592 || all params: 768,575,488 || trainable%: 0.6139
  0%|          | 0/54 [00:00<?, ?it/s]/home/pandeys2/Workspace/salai/.venv/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  2%|â–         | 1/54 [00:04<03:43,  4.21s/it]  4%|â–Ž         | 2/54 [00:07<03:21,  3.87s/it]  6%|â–Œ         | 3/54 [00:11<03:12,  3.77s/it]  7%|â–‹         | 4/54 [00:15<03:06,  3.73s/it]  9%|â–‰         | 5/54 [00:18<03:03,  3.74s/it] 11%|â–ˆ         | 6/54 [00:22<02:57,  3.71s/it] 13%|â–ˆâ–Ž        | 7/54 [00:26<02:54,  3.71s/it] 15%|â–ˆâ–        | 8/54 [00:29<02:49,  3.68s/it] 17%|â–ˆâ–‹        | 9/54 [00:33<02:45,  3.69s/it] 19%|â–ˆâ–Š        | 10/54 [00:37<02:46,  3.78s/it]                                                19%|â–ˆâ–Š        | 10/54 [00:37<02:46,  3.78s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:41<02:40,  3.74s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:44<02:36,  3.72s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:48<02:31,  3.69s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:52<02:26,  3.67s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:56<02:28,  3.82s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [01:00<02:28,  3.92s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [01:04<02:22,  3.84s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18/54 [01:07<02:16,  3.79s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [01:11<02:10,  3.74s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [01:15<02:06,  3.72s/it]                                                37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [01:15<02:06,  3.72s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [01:18<02:01,  3.69s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [01:22<01:57,  3.67s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 23/54 [01:25<01:53,  3.66s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [01:29<01:49,  3.66s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [01:33<01:46,  3.66s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [01:36<01:42,  3.66s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [01:40<01:38,  3.66s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [01:44<01:34,  3.64s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 29/54 [01:47<01:31,  3.65s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [01:51<01:28,  3.67s/it]                                                56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [01:51<01:28,  3.67s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [01:55<01:24,  3.66s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [01:59<01:21,  3.69s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [02:02<01:19,  3.78s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 34/54 [02:06<01:16,  3.83s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [02:10<01:11,  3.77s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [02:14<01:07,  3.75s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [02:17<01:03,  3.73s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [02:21<00:59,  3.69s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [02:25<00:55,  3.68s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [02:29<00:52,  3.76s/it]                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [02:29<00:52,  3.76s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [02:32<00:48,  3.74s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [02:36<00:44,  3.73s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [02:40<00:41,  3.75s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [02:43<00:37,  3.71s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 45/54 [02:47<00:34,  3.78s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [02:51<00:29,  3.75s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [02:55<00:26,  3.72s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [02:58<00:22,  3.70s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [03:02<00:18,  3.67s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 50/54 [03:06<00:14,  3.66s/it]                                                93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 50/54 [03:06<00:14,  3.66s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [03:09<00:11,  3.67s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [03:13<00:07,  3.65s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [03:16<00:03,  3.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [03:17<00:00,  2.67s/it]Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
{'loss': 2.7004, 'grad_norm': 1.5762476921081543, 'learning_rate': 0.000625, 'epoch': 0.19}
{'loss': 1.263, 'grad_norm': 1.225775122642517, 'learning_rate': 0.0004861111111111111, 'epoch': 0.38}
{'loss': 0.9886, 'grad_norm': 1.1374257802963257, 'learning_rate': 0.00034722222222222224, 'epoch': 0.56}
{'loss': 0.8409, 'grad_norm': 1.7222853899002075, 'learning_rate': 0.00020833333333333335, 'epoch': 0.75}
{'loss': 0.7504, 'grad_norm': 0.838419497013092, 'learning_rate': 6.944444444444444e-05, 'epoch': 0.94}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:23,  1.07s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:27,  1.31s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:07<00:32,  1.63s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:09<00:34,  1.81s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:30,  1.68s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.58s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.61s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.51s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:17<00:24,  1.72s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.68s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:20<00:21,  1.76s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:22<00:20,  1.85s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:24<00:19,  1.93s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:27<00:19,  2.17s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:29<00:16,  2.02s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:31<00:14,  2.05s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:33<00:12,  2.01s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:34<00:09,  1.84s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:38<00:09,  2.34s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:40<00:07,  2.34s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:42<00:04,  2.11s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:43<00:02,  2.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:45<00:00,  1.97s/it][A                                               
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [04:10<00:00,  2.67s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:50<00:00,  1.97s/it][A
                                               [A                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [04:10<00:00,  2.67s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [04:10<00:00,  4.63s/it]
{'eval_loss': 0.6753695607185364, 'eval_wer': 24.928530588907947, 'eval_runtime': 52.7291, 'eval_samples_per_second': 3.774, 'eval_steps_per_second': 0.474, 'epoch': 1.0}
{'train_runtime': 250.1694, 'train_samples_per_second': 6.803, 'train_steps_per_second': 0.216, 'train_loss': 1.2547985006261755, 'epoch': 1.0}
Training complete.
Skipping all weight saves (--skip_save).
  0%|          | 0/25 [00:00<?, ?it/s]  8%|â–Š         | 2/25 [00:02<00:26,  1.15s/it] 12%|â–ˆâ–        | 3/25 [00:03<00:28,  1.32s/it] 16%|â–ˆâ–Œ        | 4/25 [00:05<00:30,  1.46s/it] 20%|â–ˆâ–ˆ        | 5/25 [00:07<00:30,  1.51s/it] 24%|â–ˆâ–ˆâ–       | 6/25 [00:09<00:32,  1.72s/it] 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:29,  1.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:12<00:26,  1.53s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:14<00:28,  1.79s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:15<00:24,  1.64s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:18<00:27,  2.00s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:20<00:26,  2.05s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:22<00:23,  1.93s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:23<00:20,  1.85s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:26<00:19,  1.94s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:28<00:19,  2.19s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:31<00:18,  2.35s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:34<00:17,  2.46s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:36<00:13,  2.28s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:37<00:10,  2.02s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:40<00:09,  2.29s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:42<00:06,  2.32s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:44<00:04,  2.15s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:46<00:02,  2.06s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:48<00:00,  2.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:52<00:00,  2.10s/it]
[sweep] Metrics written to: /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_001.csv
