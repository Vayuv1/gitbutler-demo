CMD: python /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py --model_name openai/whisper-large-v3-turbo --dataset_part base --train_fraction 0.25 --validation_samples 200 --epochs 2 --language en --task transcribe --per_device_train_batch_size 6 --gradient_accumulation_steps 6 --learning_rate 0.0005 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --seed 42 --num_proc 1 --eval_strategy epoch --eval_steps 100 --run_stage coarse --run_id coarse_029 --skip_save --metrics_csv /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_029.csv
Using the latest cached version of the module from /home/pandeys2/.cache/huggingface/modules/datasets_modules/datasets/HF-SaLAI--salai_atc0/6a6a809cccd83aaa7dae50203e4c7f7fc6313a701a3deebe3dfca35a211f125c (last modified on Wed Aug  6 19:14:44 2025) since it couldn't be found locally at HF-SaLAI/salai_atc0, or remotely on the Hugging Face Hub.
/home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py:326: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
Using device: cuda
---- PATH DEBUG ----
CWD:            /home/pandeys2/Workspace/salai
__file__:       /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py
script_dir:     /home/pandeys2/Workspace/salai/asr_finetune
repo_root:      /home/pandeys2/Workspace/salai
finetuned_dir:  /home/pandeys2/Workspace/salai/finetuned_models
OUTPUT DIR:     /home/pandeys2/Workspace/salai/finetuned_models/whisper_lora_whisper-large-v3-turbo_base
--------------------
trainable params: 3,276,800 || all params: 812,154,880 || trainable%: 0.4035
  0%|          | 0/96 [00:00<?, ?it/s]/home/pandeys2/Workspace/salai/.venv/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  1%|          | 1/96 [00:06<10:39,  6.74s/it]  2%|â–         | 2/96 [00:12<09:56,  6.34s/it]  3%|â–Ž         | 3/96 [00:18<09:37,  6.21s/it]  4%|â–         | 4/96 [00:24<09:25,  6.15s/it]  5%|â–Œ         | 5/96 [00:30<09:15,  6.10s/it]  6%|â–‹         | 6/96 [00:36<09:06,  6.08s/it]  7%|â–‹         | 7/96 [00:42<08:59,  6.06s/it]  8%|â–Š         | 8/96 [00:49<08:52,  6.05s/it]  9%|â–‰         | 9/96 [00:55<08:45,  6.04s/it] 10%|â–ˆ         | 10/96 [01:01<08:38,  6.03s/it]                                                10%|â–ˆ         | 10/96 [01:01<08:38,  6.03s/it] 11%|â–ˆâ–        | 11/96 [01:07<08:32,  6.03s/it] 12%|â–ˆâ–Ž        | 12/96 [01:13<08:26,  6.03s/it] 14%|â–ˆâ–Ž        | 13/96 [01:19<08:19,  6.02s/it] 15%|â–ˆâ–        | 14/96 [01:25<08:14,  6.03s/it] 16%|â–ˆâ–Œ        | 15/96 [01:31<08:08,  6.03s/it] 17%|â–ˆâ–‹        | 16/96 [01:37<08:02,  6.03s/it] 18%|â–ˆâ–Š        | 17/96 [01:43<07:56,  6.03s/it] 19%|â–ˆâ–‰        | 18/96 [01:49<07:49,  6.02s/it] 20%|â–ˆâ–‰        | 19/96 [01:55<07:44,  6.03s/it] 21%|â–ˆâ–ˆ        | 20/96 [02:01<07:38,  6.04s/it]                                                21%|â–ˆâ–ˆ        | 20/96 [02:01<07:38,  6.04s/it] 22%|â–ˆâ–ˆâ–       | 21/96 [02:07<07:32,  6.03s/it] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [02:13<07:25,  6.02s/it] 24%|â–ˆâ–ˆâ–       | 23/96 [02:19<07:19,  6.02s/it] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [02:25<07:13,  6.02s/it] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [02:31<07:06,  6.01s/it] 27%|â–ˆâ–ˆâ–‹       | 26/96 [02:37<07:01,  6.02s/it] 28%|â–ˆâ–ˆâ–Š       | 27/96 [02:43<06:55,  6.02s/it] 29%|â–ˆâ–ˆâ–‰       | 28/96 [02:49<06:48,  6.01s/it] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [02:55<06:44,  6.04s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [03:01<06:39,  6.05s/it]                                                31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [03:01<06:39,  6.05s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [03:07<06:33,  6.05s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [03:13<06:26,  6.04s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [03:19<06:21,  6.06s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [03:25<06:16,  6.08s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [03:31<06:09,  6.06s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [03:37<06:02,  6.04s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [03:43<05:56,  6.04s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [03:49<05:50,  6.04s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [03:56<05:44,  6.04s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [04:02<05:37,  6.04s/it]                                                42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [04:02<05:37,  6.04s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [04:08<05:31,  6.02s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [04:14<05:25,  6.02s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [04:20<05:18,  6.01s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [04:26<05:12,  6.01s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [04:32<05:06,  6.00s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [04:38<05:00,  6.02s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [04:44<04:55,  6.02s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [04:45<03:40,  4.59s/it]Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.
Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
{'loss': 2.5857, 'grad_norm': 2.3536758422851562, 'learning_rate': 0.000453125, 'epoch': 0.21}
{'loss': 1.2285, 'grad_norm': 2.1441774368286133, 'learning_rate': 0.0004010416666666667, 'epoch': 0.42}
{'loss': 0.8043, 'grad_norm': 1.829382061958313, 'learning_rate': 0.00034895833333333334, 'epoch': 0.63}
{'loss': 0.6903, 'grad_norm': 1.6106468439102173, 'learning_rate': 0.000296875, 'epoch': 0.85}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:17,  1.35it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:22,  1.02s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:25,  1.20s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:05<00:25,  1.29s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.38s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.40s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:24,  1.41s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:22,  1.43s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.43s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.46s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:19,  1.47s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.47s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.47s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:13,  1.52s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:12,  1.51s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:09,  1.51s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:28<00:07,  1.49s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:06,  1.54s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:31<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:03,  1.53s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:34<00:01,  1.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.29s/it][A                                               
                                               [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [05:26<03:40,  4.59s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.29s/it][A
                                               [A 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [05:32<13:34, 17.33s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [05:38<10:41, 13.93s/it]                                                52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [05:38<10:41, 13.93s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [05:44<08:40, 11.57s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [05:50<07:15,  9.89s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [05:56<06:15,  8.74s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [06:02<05:31,  7.90s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [06:08<05:01,  7.34s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [06:14<04:37,  6.95s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [06:20<04:20,  6.68s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [06:26<04:06,  6.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [06:32<03:54,  6.33s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [06:38<03:44,  6.22s/it]                                                62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [06:38<03:44,  6.22s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [06:44<03:35,  6.15s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [06:50<03:27,  6.09s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [06:56<03:20,  6.07s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [07:02<03:13,  6.04s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [07:08<03:06,  6.02s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [07:14<03:00,  6.03s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [07:20<02:54,  6.02s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [07:26<02:48,  6.01s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [07:32<02:41,  5.99s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [07:38<02:35,  6.00s/it]                                                73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [07:38<02:35,  6.00s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [07:44<02:29,  5.99s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [07:50<02:23,  5.98s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [07:56<02:17,  5.98s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [08:02<02:11,  5.98s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [08:08<02:05,  5.98s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [08:14<02:00,  6.00s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [08:20<01:53,  6.00s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [08:26<01:48,  6.00s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [08:32<01:41,  6.00s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [08:38<01:35,  5.99s/it]                                                83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [08:38<01:35,  5.99s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [08:44<01:29,  5.99s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [08:50<01:23,  5.98s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [08:56<01:17,  6.00s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [09:02<01:11,  5.99s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [09:08<01:05,  5.98s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [09:14<00:59,  5.98s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [09:20<00:53,  5.97s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [09:26<00:47,  5.97s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [09:32<00:41,  5.96s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [09:38<00:35,  5.96s/it]                                                94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [09:38<00:35,  5.96s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [09:44<00:29,  5.98s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [09:50<00:23,  5.97s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [09:56<00:17,  5.98s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [10:02<00:11,  5.99s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [10:08<00:05,  5.99s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:09<00:00,  4.57s/it]{'eval_loss': 0.5854998230934143, 'eval_wer': 22.641509433962266, 'eval_runtime': 40.7174, 'eval_samples_per_second': 4.887, 'eval_steps_per_second': 0.614, 'epoch': 1.0}
{'loss': 0.5713, 'grad_norm': 1.2088834047317505, 'learning_rate': 0.00024479166666666665, 'epoch': 1.04}
{'loss': 0.4658, 'grad_norm': 1.553484320640564, 'learning_rate': 0.00019270833333333336, 'epoch': 1.25}
{'loss': 0.4615, 'grad_norm': 1.718039870262146, 'learning_rate': 0.00014062500000000002, 'epoch': 1.46}
{'loss': 0.4198, 'grad_norm': 1.4024003744125366, 'learning_rate': 8.854166666666667e-05, 'epoch': 1.68}
{'loss': 0.4859, 'grad_norm': 1.2909334897994995, 'learning_rate': 3.6458333333333336e-05, 'epoch': 1.89}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.37it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:22,  1.02s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.18s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:05<00:25,  1.28s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:25,  1.36s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:24,  1.39s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.39s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:22,  1.42s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.42s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.46s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:18,  1.45s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.45s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:18<00:15,  1.45s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.47s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:13,  1.52s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:12,  1.51s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.50s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:09,  1.51s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:28<00:07,  1.48s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:06,  1.53s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:31<00:04,  1.54s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:03,  1.52s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:34<00:01,  1.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:34<00:00,  1.28s/it][A                                               
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:49<00:00,  4.57s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.28s/it][A
                                               [A                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:49<00:00,  4.57s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [10:49<00:00,  6.77s/it]
{'eval_loss': 0.519493043422699, 'eval_wer': 20.697541452258434, 'eval_runtime': 40.4484, 'eval_samples_per_second': 4.92, 'eval_steps_per_second': 0.618, 'epoch': 2.0}
{'train_runtime': 649.7191, 'train_samples_per_second': 5.239, 'train_steps_per_second': 0.148, 'train_loss': 0.8272161682446798, 'epoch': 2.0}
Training complete.
Skipping all weight saves (--skip_save).
  0%|          | 0/25 [00:00<?, ?it/s]  8%|â–Š         | 2/25 [00:01<00:16,  1.37it/s] 12%|â–ˆâ–        | 3/25 [00:02<00:22,  1.02s/it] 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.18s/it] 20%|â–ˆâ–ˆ        | 5/25 [00:05<00:25,  1.29s/it] 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.37s/it] 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.40s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.41s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:22,  1.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.46s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:19,  1.47s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.47s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.48s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:13,  1.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:12,  1.51s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:09,  1.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:28<00:07,  1.49s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:06,  1.53s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:31<00:04,  1.54s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:03,  1.52s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:34<00:01,  1.47s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.54s/it]
[sweep] Metrics written to: /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_029.csv
