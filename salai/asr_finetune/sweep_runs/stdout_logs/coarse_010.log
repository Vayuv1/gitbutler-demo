CMD: python /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py --model_name openai/whisper-medium.en --dataset_part base --train_fraction 0.25 --validation_samples 200 --epochs 2 --language en --task transcribe --per_device_train_batch_size 8 --gradient_accumulation_steps 4 --learning_rate 0.001 --lora_r 32 --lora_alpha 64 --lora_dropout 0.05 --seed 42 --num_proc 1 --eval_strategy epoch --eval_steps 100 --run_stage coarse --run_id coarse_010 --skip_save --metrics_csv /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_010.csv
Using the latest cached version of the module from /home/pandeys2/.cache/huggingface/modules/datasets_modules/datasets/HF-SaLAI--salai_atc0/6a6a809cccd83aaa7dae50203e4c7f7fc6313a701a3deebe3dfca35a211f125c (last modified on Wed Aug  6 19:14:44 2025) since it couldn't be found locally at HF-SaLAI/salai_atc0, or remotely on the Hugging Face Hub.
/home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py:326: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
Using device: cuda
---- PATH DEBUG ----
CWD:            /home/pandeys2/Workspace/salai
__file__:       /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py
script_dir:     /home/pandeys2/Workspace/salai/asr_finetune
repo_root:      /home/pandeys2/Workspace/salai
finetuned_dir:  /home/pandeys2/Workspace/salai/finetuned_models
OUTPUT DIR:     /home/pandeys2/Workspace/salai/finetuned_models/whisper_lora_whisper-medium.en_base
--------------------
trainable params: 9,437,184 || all params: 773,294,080 || trainable%: 1.2204
  0%|          | 0/108 [00:00<?, ?it/s]/home/pandeys2/Workspace/salai/.venv/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  1%|          | 1/108 [00:04<07:30,  4.21s/it]  2%|▏         | 2/108 [00:07<06:52,  3.90s/it]  3%|▎         | 3/108 [00:11<06:36,  3.77s/it]  4%|▎         | 4/108 [00:15<06:26,  3.71s/it]  5%|▍         | 5/108 [00:18<06:19,  3.68s/it]  6%|▌         | 6/108 [00:22<06:13,  3.66s/it]  6%|▋         | 7/108 [00:26<06:08,  3.65s/it]  7%|▋         | 8/108 [00:29<06:03,  3.64s/it]  8%|▊         | 9/108 [00:33<05:59,  3.63s/it]  9%|▉         | 10/108 [00:36<05:55,  3.63s/it]                                                  9%|▉         | 10/108 [00:36<05:55,  3.63s/it] 10%|█         | 11/108 [00:40<05:51,  3.63s/it] 11%|█         | 12/108 [00:44<05:47,  3.62s/it] 12%|█▏        | 13/108 [00:47<05:44,  3.62s/it] 13%|█▎        | 14/108 [00:51<05:40,  3.62s/it] 14%|█▍        | 15/108 [00:54<05:37,  3.63s/it] 15%|█▍        | 16/108 [00:58<05:34,  3.63s/it] 16%|█▌        | 17/108 [01:02<05:30,  3.63s/it] 17%|█▋        | 18/108 [01:05<05:26,  3.63s/it] 18%|█▊        | 19/108 [01:09<05:22,  3.62s/it] 19%|█▊        | 20/108 [01:13<05:19,  3.63s/it]                                                 19%|█▊        | 20/108 [01:13<05:19,  3.63s/it] 19%|█▉        | 21/108 [01:16<05:16,  3.63s/it] 20%|██        | 22/108 [01:20<05:12,  3.63s/it] 21%|██▏       | 23/108 [01:24<05:10,  3.65s/it] 22%|██▏       | 24/108 [01:27<05:05,  3.64s/it] 23%|██▎       | 25/108 [01:31<05:04,  3.67s/it] 24%|██▍       | 26/108 [01:35<05:00,  3.66s/it] 25%|██▌       | 27/108 [01:38<04:55,  3.65s/it] 26%|██▌       | 28/108 [01:42<04:51,  3.65s/it] 27%|██▋       | 29/108 [01:46<04:48,  3.65s/it] 28%|██▊       | 30/108 [01:49<04:44,  3.65s/it]                                                 28%|██▊       | 30/108 [01:49<04:44,  3.65s/it] 29%|██▊       | 31/108 [01:53<04:40,  3.65s/it] 30%|██▉       | 32/108 [01:56<04:37,  3.65s/it] 31%|███       | 33/108 [02:00<04:33,  3.65s/it] 31%|███▏      | 34/108 [02:04<04:28,  3.63s/it] 32%|███▏      | 35/108 [02:07<04:25,  3.63s/it] 33%|███▎      | 36/108 [02:11<04:21,  3.64s/it] 34%|███▍      | 37/108 [02:15<04:17,  3.63s/it] 35%|███▌      | 38/108 [02:18<04:13,  3.62s/it] 36%|███▌      | 39/108 [02:22<04:09,  3.62s/it] 37%|███▋      | 40/108 [02:25<04:06,  3.62s/it]                                                 37%|███▋      | 40/108 [02:25<04:06,  3.62s/it] 38%|███▊      | 41/108 [02:29<04:02,  3.62s/it] 39%|███▉      | 42/108 [02:33<03:59,  3.62s/it] 40%|███▉      | 43/108 [02:36<03:55,  3.62s/it] 41%|████      | 44/108 [02:40<03:51,  3.62s/it] 42%|████▏     | 45/108 [02:44<03:47,  3.62s/it] 43%|████▎     | 46/108 [02:47<03:43,  3.61s/it] 44%|████▎     | 47/108 [02:51<03:40,  3.61s/it] 44%|████▍     | 48/108 [02:54<03:36,  3.61s/it] 45%|████▌     | 49/108 [02:58<03:33,  3.62s/it] 46%|████▋     | 50/108 [03:02<03:30,  3.62s/it]                                                 46%|████▋     | 50/108 [03:02<03:30,  3.62s/it] 47%|████▋     | 51/108 [03:05<03:28,  3.65s/it] 48%|████▊     | 52/108 [03:09<03:23,  3.64s/it] 49%|████▉     | 53/108 [03:12<03:18,  3.61s/it] 50%|█████     | 54/108 [03:13<02:23,  2.66s/it]Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
{'loss': 2.1812, 'grad_norm': 1.3934932947158813, 'learning_rate': 0.0009166666666666666, 'epoch': 0.19}
{'loss': 0.8949, 'grad_norm': 1.547013521194458, 'learning_rate': 0.0008333333333333334, 'epoch': 0.38}
{'loss': 0.7826, 'grad_norm': 1.1201666593551636, 'learning_rate': 0.0007407407407407407, 'epoch': 0.56}
{'loss': 0.6532, 'grad_norm': 0.9596272706985474, 'learning_rate': 0.0006481481481481481, 'epoch': 0.75}
{'loss': 0.5668, 'grad_norm': 1.2467204332351685, 'learning_rate': 0.0005555555555555556, 'epoch': 0.94}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:01<00:18,  1.23it/s][A
 12%|█▏        | 3/25 [00:02<00:22,  1.04s/it][A
 16%|█▌        | 4/25 [00:04<00:27,  1.30s/it][A
 20%|██        | 5/25 [00:06<00:28,  1.43s/it][A
 24%|██▍       | 6/25 [00:08<00:31,  1.67s/it][A
 28%|██▊       | 7/25 [00:10<00:29,  1.64s/it][A
 32%|███▏      | 8/25 [00:16<00:52,  3.11s/it][A
 36%|███▌      | 9/25 [00:18<00:42,  2.66s/it][A
 40%|████      | 10/25 [00:19<00:33,  2.25s/it][A
 44%|████▍     | 11/25 [00:21<00:31,  2.24s/it][A
 48%|████▊     | 12/25 [00:23<00:26,  2.02s/it][A
 52%|█████▏    | 13/25 [00:24<00:22,  1.88s/it][A
 56%|█████▌    | 14/25 [00:30<00:35,  3.20s/it][A
 60%|██████    | 15/25 [00:32<00:28,  2.83s/it][A
 64%|██████▍   | 16/25 [00:35<00:24,  2.73s/it][A
 68%|██████▊   | 17/25 [00:37<00:19,  2.45s/it][A
 72%|███████▏  | 18/25 [00:39<00:15,  2.28s/it][A
 76%|███████▌  | 19/25 [00:41<00:12,  2.16s/it][A
 80%|████████  | 20/25 [00:42<00:09,  1.94s/it][A
 84%|████████▍ | 21/25 [00:45<00:08,  2.22s/it][A
 88%|████████▊ | 22/25 [00:47<00:06,  2.23s/it][A
 92%|█████████▏| 23/25 [00:49<00:04,  2.02s/it][A
 96%|█████████▌| 24/25 [00:50<00:01,  1.83s/it][A
100%|██████████| 25/25 [00:51<00:00,  1.66s/it][A                                                
                                               [A 50%|█████     | 54/108 [04:11<02:23,  2.66s/it]
100%|██████████| 25/25 [00:55<00:00,  1.66s/it][A
                                               [A 51%|█████     | 55/108 [04:15<18:01, 20.41s/it] 52%|█████▏    | 56/108 [04:18<13:19, 15.38s/it] 53%|█████▎    | 57/108 [04:22<10:04, 11.85s/it] 54%|█████▎    | 58/108 [04:26<07:49,  9.39s/it] 55%|█████▍    | 59/108 [04:29<06:14,  7.65s/it] 56%|█████▌    | 60/108 [04:33<05:09,  6.45s/it]                                                 56%|█████▌    | 60/108 [04:33<05:09,  6.45s/it] 56%|█████▋    | 61/108 [04:37<04:23,  5.60s/it] 57%|█████▋    | 62/108 [04:40<03:50,  5.01s/it] 58%|█████▊    | 63/108 [04:44<03:26,  4.59s/it] 59%|█████▉    | 64/108 [04:47<03:09,  4.30s/it] 60%|██████    | 65/108 [04:51<02:56,  4.10s/it] 61%|██████    | 66/108 [04:55<02:46,  3.96s/it] 62%|██████▏   | 67/108 [04:58<02:37,  3.85s/it] 63%|██████▎   | 68/108 [05:02<02:30,  3.77s/it] 64%|██████▍   | 69/108 [05:05<02:25,  3.73s/it] 65%|██████▍   | 70/108 [05:09<02:20,  3.69s/it]                                                 65%|██████▍   | 70/108 [05:09<02:20,  3.69s/it] 66%|██████▌   | 71/108 [05:13<02:15,  3.67s/it] 67%|██████▋   | 72/108 [05:16<02:11,  3.65s/it] 68%|██████▊   | 73/108 [05:20<02:07,  3.63s/it] 69%|██████▊   | 74/108 [05:24<02:03,  3.64s/it] 69%|██████▉   | 75/108 [05:27<01:59,  3.62s/it] 70%|███████   | 76/108 [05:31<01:55,  3.62s/it] 71%|███████▏  | 77/108 [05:34<01:52,  3.64s/it] 72%|███████▏  | 78/108 [05:38<01:49,  3.64s/it] 73%|███████▎  | 79/108 [05:42<01:45,  3.64s/it] 74%|███████▍  | 80/108 [05:45<01:41,  3.63s/it]                                                 74%|███████▍  | 80/108 [05:45<01:41,  3.63s/it] 75%|███████▌  | 81/108 [05:49<01:37,  3.61s/it] 76%|███████▌  | 82/108 [05:53<01:34,  3.62s/it] 77%|███████▋  | 83/108 [05:56<01:30,  3.62s/it] 78%|███████▊  | 84/108 [06:00<01:26,  3.61s/it] 79%|███████▊  | 85/108 [06:03<01:22,  3.61s/it] 80%|███████▉  | 86/108 [06:07<01:19,  3.60s/it] 81%|████████  | 87/108 [06:11<01:16,  3.62s/it] 81%|████████▏ | 88/108 [06:14<01:12,  3.62s/it] 82%|████████▏ | 89/108 [06:18<01:08,  3.62s/it] 83%|████████▎ | 90/108 [06:21<01:05,  3.62s/it]                                                 83%|████████▎ | 90/108 [06:21<01:05,  3.62s/it] 84%|████████▍ | 91/108 [06:25<01:01,  3.62s/it] 85%|████████▌ | 92/108 [06:29<00:57,  3.62s/it] 86%|████████▌ | 93/108 [06:32<00:54,  3.61s/it] 87%|████████▋ | 94/108 [06:36<00:50,  3.62s/it] 88%|████████▊ | 95/108 [06:40<00:46,  3.61s/it] 89%|████████▉ | 96/108 [06:43<00:43,  3.61s/it] 90%|████████▉ | 97/108 [06:47<00:39,  3.62s/it] 91%|█████████ | 98/108 [06:50<00:36,  3.63s/it] 92%|█████████▏| 99/108 [06:54<00:32,  3.63s/it] 93%|█████████▎| 100/108 [06:58<00:29,  3.64s/it]                                                  93%|█████████▎| 100/108 [06:58<00:29,  3.64s/it] 94%|█████████▎| 101/108 [07:01<00:25,  3.63s/it] 94%|█████████▍| 102/108 [07:05<00:21,  3.63s/it] 95%|█████████▌| 103/108 [07:09<00:18,  3.62s/it] 96%|█████████▋| 104/108 [07:12<00:14,  3.64s/it] 97%|█████████▋| 105/108 [07:16<00:10,  3.64s/it] 98%|█████████▊| 106/108 [07:19<00:07,  3.63s/it] 99%|█████████▉| 107/108 [07:23<00:03,  3.59s/it]100%|██████████| 108/108 [07:23<00:00,  2.65s/it]{'eval_loss': 0.5353672504425049, 'eval_wer': 35.79188107489995, 'eval_runtime': 57.8547, 'eval_samples_per_second': 3.44, 'eval_steps_per_second': 0.432, 'epoch': 1.0}
{'loss': 0.3369, 'grad_norm': 0.6684492826461792, 'learning_rate': 0.000462962962962963, 'epoch': 1.11}
{'loss': 0.3417, 'grad_norm': 0.653965413570404, 'learning_rate': 0.00037037037037037035, 'epoch': 1.3}
{'loss': 0.3149, 'grad_norm': 0.8346590995788574, 'learning_rate': 0.0002777777777777778, 'epoch': 1.49}
{'loss': 0.3062, 'grad_norm': 0.5724547505378723, 'learning_rate': 0.00018518518518518518, 'epoch': 1.68}
{'loss': 0.3084, 'grad_norm': 0.8332736492156982, 'learning_rate': 9.259259259259259e-05, 'epoch': 1.86}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:01<00:18,  1.22it/s][A
 12%|█▏        | 3/25 [00:03<00:23,  1.07s/it][A
 16%|█▌        | 4/25 [00:04<00:27,  1.33s/it][A
 20%|██        | 5/25 [00:06<00:28,  1.45s/it][A
 24%|██▍       | 6/25 [00:08<00:31,  1.67s/it][A
 28%|██▊       | 7/25 [00:10<00:29,  1.63s/it][A
 32%|███▏      | 8/25 [00:11<00:26,  1.55s/it][A
 36%|███▌      | 9/25 [00:13<00:25,  1.59s/it][A
 40%|████      | 10/25 [00:14<00:22,  1.51s/it][A
 44%|████▍     | 11/25 [00:16<00:24,  1.71s/it][A
 48%|████▊     | 12/25 [00:18<00:21,  1.66s/it][A
 52%|█████▏    | 13/25 [00:19<00:19,  1.65s/it][A
 56%|█████▌    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|██████    | 15/25 [00:23<00:17,  1.72s/it][A
 64%|██████▍   | 16/25 [00:26<00:18,  2.00s/it][A
 68%|██████▊   | 17/25 [00:27<00:15,  1.92s/it][A
 72%|███████▏  | 18/25 [00:29<00:13,  1.91s/it][A
 76%|███████▌  | 19/25 [00:31<00:11,  1.91s/it][A
 80%|████████  | 20/25 [00:32<00:08,  1.76s/it][A
 84%|████████▍ | 21/25 [00:35<00:08,  2.08s/it][A
 88%|████████▊ | 22/25 [00:38<00:06,  2.12s/it][A
 92%|█████████▏| 23/25 [00:39<00:03,  1.95s/it][A
 96%|█████████▌| 24/25 [00:41<00:01,  1.81s/it][A
100%|██████████| 25/25 [00:42<00:00,  1.65s/it][A                                                 
                                               [A100%|██████████| 108/108 [08:12<00:00,  2.65s/it]
100%|██████████| 25/25 [00:45<00:00,  1.65s/it][A
                                               [A                                                 100%|██████████| 108/108 [08:12<00:00,  2.65s/it]100%|██████████| 108/108 [08:12<00:00,  4.56s/it]
{'eval_loss': 0.477985143661499, 'eval_wer': 18.753573470554603, 'eval_runtime': 48.3172, 'eval_samples_per_second': 4.119, 'eval_steps_per_second': 0.517, 'epoch': 2.0}
{'train_runtime': 492.2471, 'train_samples_per_second': 6.915, 'train_steps_per_second': 0.219, 'train_loss': 0.6380701241669832, 'epoch': 2.0}
Training complete.
Skipping all weight saves (--skip_save).
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:01<00:18,  1.22it/s] 12%|█▏        | 3/25 [00:03<00:23,  1.06s/it] 16%|█▌        | 4/25 [00:04<00:27,  1.33s/it] 20%|██        | 5/25 [00:06<00:28,  1.45s/it] 24%|██▍       | 6/25 [00:08<00:31,  1.68s/it] 28%|██▊       | 7/25 [00:10<00:29,  1.63s/it] 32%|███▏      | 8/25 [00:11<00:26,  1.55s/it] 36%|███▌      | 9/25 [00:13<00:25,  1.58s/it] 40%|████      | 10/25 [00:14<00:22,  1.50s/it] 44%|████▍     | 11/25 [00:16<00:23,  1.71s/it] 48%|████▊     | 12/25 [00:18<00:21,  1.65s/it] 52%|█████▏    | 13/25 [00:19<00:19,  1.65s/it] 56%|█████▌    | 14/25 [00:21<00:17,  1.62s/it] 60%|██████    | 15/25 [00:23<00:17,  1.74s/it] 64%|██████▍   | 16/25 [00:26<00:18,  2.01s/it] 68%|██████▊   | 17/25 [00:27<00:15,  1.93s/it] 72%|███████▏  | 18/25 [00:29<00:13,  1.91s/it] 76%|███████▌  | 19/25 [00:31<00:11,  1.91s/it] 80%|████████  | 20/25 [00:32<00:08,  1.76s/it] 84%|████████▍ | 21/25 [00:35<00:08,  2.08s/it] 88%|████████▊ | 22/25 [00:38<00:06,  2.12s/it] 92%|█████████▏| 23/25 [00:39<00:03,  1.95s/it] 96%|█████████▌| 24/25 [00:41<00:01,  1.81s/it]100%|██████████| 25/25 [00:42<00:00,  1.64s/it]100%|██████████| 25/25 [00:45<00:00,  1.83s/it]
[sweep] Metrics written to: /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_010.csv
