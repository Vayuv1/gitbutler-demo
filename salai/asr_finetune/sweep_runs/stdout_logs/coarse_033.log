CMD: python /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py --model_name openai/whisper-large-v3-turbo --dataset_part base --train_fraction 0.5 --validation_samples 200 --epochs 1 --language en --task transcribe --per_device_train_batch_size 6 --gradient_accumulation_steps 6 --learning_rate 0.0005 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --seed 42 --num_proc 1 --eval_strategy epoch --eval_steps 100 --run_stage coarse --run_id coarse_033 --skip_save --metrics_csv /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_033.csv
Using the latest cached version of the module from /home/pandeys2/.cache/huggingface/modules/datasets_modules/datasets/HF-SaLAI--salai_atc0/6a6a809cccd83aaa7dae50203e4c7f7fc6313a701a3deebe3dfca35a211f125c (last modified on Wed Aug  6 19:14:44 2025) since it couldn't be found locally at HF-SaLAI/salai_atc0, or remotely on the Hugging Face Hub.
Using device: cuda
---- PATH DEBUG ----
CWD:            /home/pandeys2/Workspace/salai
__file__:       /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py
script_dir:     /home/pandeys2/Workspace/salai/asr_finetune
repo_root:      /home/pandeys2/Workspace/salai
finetuned_dir:  /home/pandeys2/Workspace/salai/finetuned_models
OUTPUT DIR:     /home/pandeys2/Workspace/salai/finetuned_models/whisper_lora_whisper-large-v3-turbo_base
--------------------
Map:   0%|          | 0/3404 [00:00<?, ? examples/s]/home/pandeys2/Workspace/salai/.venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:503: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.
  warnings.warn(
Map:   0%|          | 1/3404 [00:00<35:46,  1.59 examples/s]Map:   0%|          | 12/3404 [00:00<02:43, 20.75 examples/s]Map:   1%|▏         | 48/3404 [00:00<00:37, 88.76 examples/s]Map:   2%|▏         | 83/3404 [00:00<00:22, 145.54 examples/s]Map:   3%|▎         | 118/3404 [00:01<00:17, 192.64 examples/s]Map:   5%|▍         | 155/3404 [00:01<00:13, 236.27 examples/s]Map:   6%|▌         | 191/3404 [00:01<00:12, 266.28 examples/s]Map:   7%|▋         | 231/3404 [00:01<00:10, 299.67 examples/s]Map:   8%|▊         | 270/3404 [00:01<00:09, 322.69 examples/s]Map:   9%|▉         | 309/3404 [00:01<00:09, 338.71 examples/s]Map:  10%|█         | 347/3404 [00:01<00:08, 347.54 examples/s]Map:  11%|█▏        | 387/3404 [00:01<00:08, 358.87 examples/s]Map:  13%|█▎        | 426/3404 [00:01<00:08, 366.03 examples/s]Map:  14%|█▍        | 483/3404 [00:02<00:07, 368.39 examples/s]Map:  16%|█▌        | 536/3404 [00:02<00:07, 359.99 examples/s]Map:  17%|█▋        | 575/3404 [00:02<00:07, 365.72 examples/s]Map:  18%|█▊        | 629/3404 [00:02<00:07, 358.60 examples/s]Map:  20%|█▉        | 668/3404 [00:02<00:07, 363.63 examples/s]Map:  21%|██        | 706/3404 [00:02<00:07, 366.36 examples/s]Map:  22%|██▏       | 744/3404 [00:02<00:07, 367.45 examples/s]Map:  23%|██▎       | 782/3404 [00:02<00:07, 369.33 examples/s]Map:  24%|██▍       | 820/3404 [00:02<00:06, 371.44 examples/s]Map:  25%|██▌       | 860/3404 [00:03<00:06, 375.43 examples/s]Map:  26%|██▋       | 899/3404 [00:03<00:06, 377.26 examples/s]Map:  28%|██▊       | 937/3404 [00:03<00:06, 377.68 examples/s]Map:  29%|██▉       | 994/3404 [00:03<00:06, 371.84 examples/s]Map:  31%|███       | 1049/3404 [00:05<00:27, 84.35 examples/s]Map:  32%|███▏      | 1099/3404 [00:05<00:20, 113.59 examples/s]Map:  34%|███▎      | 1148/3404 [00:05<00:15, 147.85 examples/s]Map:  35%|███▌      | 1197/3404 [00:05<00:11, 186.97 examples/s]Map:  37%|███▋      | 1247/3404 [00:05<00:09, 230.58 examples/s]Map:  38%|███▊      | 1297/3404 [00:05<00:07, 274.54 examples/s]Map:  40%|███▉      | 1347/3404 [00:05<00:06, 317.11 examples/s]Map:  41%|████      | 1397/3404 [00:05<00:05, 354.78 examples/s]Map:  42%|████▏     | 1446/3404 [00:05<00:05, 385.02 examples/s]Map:  44%|████▍     | 1495/3404 [00:05<00:04, 409.38 examples/s]Map:  45%|████▌     | 1545/3404 [00:06<00:04, 430.13 examples/s]Map:  47%|████▋     | 1595/3404 [00:06<00:04, 446.46 examples/s]Map:  48%|████▊     | 1645/3404 [00:06<00:03, 459.68 examples/s]Map:  50%|████▉     | 1694/3404 [00:06<00:03, 466.54 examples/s]Map:  51%|█████▏    | 1745/3404 [00:06<00:03, 476.14 examples/s]Map:  53%|█████▎    | 1795/3404 [00:06<00:03, 482.75 examples/s]Map:  54%|█████▍    | 1845/3404 [00:06<00:03, 485.43 examples/s]Map:  56%|█████▌    | 1895/3404 [00:06<00:03, 488.46 examples/s]Map:  58%|█████▊    | 1967/3404 [00:06<00:03, 478.59 examples/s]Map:  59%|█████▉    | 2024/3404 [00:08<00:15, 86.69 examples/s] Map:  61%|██████    | 2073/3404 [00:08<00:11, 111.32 examples/s]Map:  62%|██████▏   | 2123/3404 [00:09<00:08, 142.43 examples/s]Map:  64%|██████▍   | 2173/3404 [00:09<00:06, 179.06 examples/s]Map:  65%|██████▌   | 2223/3404 [00:09<00:05, 219.85 examples/s]Map:  67%|██████▋   | 2273/3404 [00:09<00:04, 262.07 examples/s]Map:  68%|██████▊   | 2323/3404 [00:09<00:03, 303.26 examples/s]Map:  70%|██████▉   | 2373/3404 [00:09<00:03, 341.56 examples/s]Map:  71%|███████   | 2422/3404 [00:09<00:02, 373.85 examples/s]Map:  73%|███████▎  | 2471/3404 [00:09<00:02, 400.22 examples/s]Map:  74%|███████▍  | 2519/3404 [00:09<00:02, 420.39 examples/s]Map:  75%|███████▌  | 2568/3404 [00:09<00:01, 436.27 examples/s]Map:  77%|███████▋  | 2618/3404 [00:10<00:01, 450.66 examples/s]Map:  78%|███████▊  | 2668/3404 [00:10<00:01, 462.56 examples/s]Map:  80%|███████▉  | 2719/3404 [00:10<00:01, 473.71 examples/s]Map:  82%|████████▏ | 2792/3404 [00:10<00:01, 476.91 examples/s]Map:  83%|████████▎ | 2842/3404 [00:10<00:01, 478.31 examples/s]Map:  85%|████████▍ | 2892/3404 [00:10<00:01, 479.76 examples/s]Map:  87%|████████▋ | 2957/3404 [00:10<00:00, 458.06 examples/s]Map:  89%|████████▉ | 3024/3404 [00:12<00:04, 87.02 examples/s] Map:  90%|█████████ | 3074/3404 [00:12<00:02, 111.05 examples/s]Map:  92%|█████████▏| 3123/3404 [00:12<00:02, 139.97 examples/s]Map:  93%|█████████▎| 3166/3404 [00:13<00:01, 168.25 examples/s]Map:  95%|█████████▍| 3227/3404 [00:13<00:00, 208.90 examples/s]Map:  97%|█████████▋| 3287/3404 [00:13<00:00, 245.92 examples/s]Map:  98%|█████████▊| 3346/3404 [00:13<00:00, 276.10 examples/s]Map: 100%|█████████▉| 3403/3404 [00:13<00:00, 300.09 examples/s]Map: 100%|██████████| 3404/3404 [00:15<00:00, 223.06 examples/s]
/home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py:326: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
trainable params: 3,276,800 || all params: 812,154,880 || trainable%: 0.4035
  0%|          | 0/95 [00:00<?, ?it/s]/home/pandeys2/Workspace/salai/.venv/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  1%|          | 1/95 [00:06<10:24,  6.64s/it]  2%|▏         | 2/95 [00:12<09:43,  6.28s/it]  3%|▎         | 3/95 [00:18<09:27,  6.16s/it]  4%|▍         | 4/95 [00:24<09:17,  6.13s/it]  5%|▌         | 5/95 [00:30<09:09,  6.11s/it]  6%|▋         | 6/95 [00:36<09:02,  6.10s/it]  7%|▋         | 7/95 [00:42<08:54,  6.08s/it]  8%|▊         | 8/95 [00:49<08:48,  6.07s/it]  9%|▉         | 9/95 [00:55<08:41,  6.07s/it] 11%|█         | 10/95 [01:01<08:34,  6.05s/it]                                                11%|█         | 10/95 [01:01<08:34,  6.05s/it] 12%|█▏        | 11/95 [01:07<08:28,  6.05s/it] 13%|█▎        | 12/95 [01:13<08:22,  6.05s/it] 14%|█▎        | 13/95 [01:19<08:15,  6.05s/it] 15%|█▍        | 14/95 [01:25<08:08,  6.04s/it] 16%|█▌        | 15/95 [01:31<08:02,  6.03s/it] 17%|█▋        | 16/95 [01:37<07:57,  6.04s/it] 18%|█▊        | 17/95 [01:43<07:52,  6.06s/it] 19%|█▉        | 18/95 [01:49<07:45,  6.05s/it] 20%|██        | 19/95 [01:55<07:39,  6.05s/it] 21%|██        | 20/95 [02:01<07:33,  6.05s/it]                                                21%|██        | 20/95 [02:01<07:33,  6.05s/it] 22%|██▏       | 21/95 [02:07<07:27,  6.05s/it] 23%|██▎       | 22/95 [02:13<07:21,  6.05s/it] 24%|██▍       | 23/95 [02:19<07:15,  6.04s/it] 25%|██▌       | 24/95 [02:25<07:08,  6.04s/it] 26%|██▋       | 25/95 [02:31<07:02,  6.04s/it] 27%|██▋       | 26/95 [02:37<06:56,  6.03s/it] 28%|██▊       | 27/95 [02:43<06:49,  6.03s/it] 29%|██▉       | 28/95 [02:49<06:43,  6.02s/it] 31%|███       | 29/95 [02:55<06:37,  6.03s/it] 32%|███▏      | 30/95 [03:01<06:31,  6.02s/it]                                                32%|███▏      | 30/95 [03:01<06:31,  6.02s/it] 33%|███▎      | 31/95 [03:07<06:24,  6.02s/it] 34%|███▎      | 32/95 [03:13<06:18,  6.01s/it] 35%|███▍      | 33/95 [03:19<06:12,  6.01s/it] 36%|███▌      | 34/95 [03:25<06:08,  6.04s/it] 37%|███▋      | 35/95 [03:31<06:02,  6.04s/it] 38%|███▊      | 36/95 [03:38<05:55,  6.03s/it] 39%|███▉      | 37/95 [03:44<05:49,  6.03s/it] 40%|████      | 38/95 [03:50<05:42,  6.02s/it] 41%|████      | 39/95 [03:56<05:37,  6.02s/it] 42%|████▏     | 40/95 [04:02<05:31,  6.03s/it]                                                42%|████▏     | 40/95 [04:02<05:31,  6.03s/it] 43%|████▎     | 41/95 [04:08<05:25,  6.03s/it] 44%|████▍     | 42/95 [04:14<05:19,  6.03s/it] 45%|████▌     | 43/95 [04:20<05:13,  6.02s/it] 46%|████▋     | 44/95 [04:26<05:07,  6.03s/it] 47%|████▋     | 45/95 [04:32<05:02,  6.04s/it] 48%|████▊     | 46/95 [04:38<04:56,  6.06s/it] 49%|████▉     | 47/95 [04:44<04:50,  6.05s/it] 51%|█████     | 48/95 [04:50<04:43,  6.03s/it] 52%|█████▏    | 49/95 [04:56<04:37,  6.03s/it] 53%|█████▎    | 50/95 [05:02<04:30,  6.02s/it]                                                53%|█████▎    | 50/95 [05:02<04:30,  6.02s/it] 54%|█████▎    | 51/95 [05:08<04:25,  6.03s/it] 55%|█████▍    | 52/95 [05:14<04:19,  6.04s/it] 56%|█████▌    | 53/95 [05:20<04:12,  6.02s/it] 57%|█████▋    | 54/95 [05:26<04:07,  6.04s/it] 58%|█████▊    | 55/95 [05:32<04:01,  6.03s/it] 59%|█████▉    | 56/95 [05:38<03:54,  6.01s/it] 60%|██████    | 57/95 [05:44<03:49,  6.03s/it] 61%|██████    | 58/95 [05:50<03:43,  6.03s/it] 62%|██████▏   | 59/95 [05:56<03:36,  6.02s/it] 63%|██████▎   | 60/95 [06:02<03:30,  6.00s/it]                                                63%|██████▎   | 60/95 [06:02<03:30,  6.00s/it] 64%|██████▍   | 61/95 [06:08<03:24,  6.02s/it] 65%|██████▌   | 62/95 [06:14<03:18,  6.02s/it] 66%|██████▋   | 63/95 [06:20<03:13,  6.04s/it] 67%|██████▋   | 64/95 [06:26<03:06,  6.03s/it] 68%|██████▊   | 65/95 [06:32<03:00,  6.02s/it] 69%|██████▉   | 66/95 [06:38<02:54,  6.02s/it] 71%|███████   | 67/95 [06:44<02:48,  6.01s/it] 72%|███████▏  | 68/95 [06:50<02:42,  6.00s/it] 73%|███████▎  | 69/95 [06:56<02:35,  5.99s/it] 74%|███████▎  | 70/95 [07:02<02:30,  6.00s/it]                                                74%|███████▎  | 70/95 [07:02<02:30,  6.00s/it] 75%|███████▍  | 71/95 [07:08<02:23,  6.00s/it] 76%|███████▌  | 72/95 [07:14<02:18,  6.00s/it] 77%|███████▋  | 73/95 [07:20<02:12,  6.00s/it] 78%|███████▊  | 74/95 [07:26<02:06,  6.01s/it] 79%|███████▉  | 75/95 [07:32<02:00,  6.00s/it] 80%|████████  | 76/95 [07:38<01:53,  6.00s/it] 81%|████████  | 77/95 [07:44<01:47,  6.00s/it] 82%|████████▏ | 78/95 [07:50<01:42,  6.02s/it] 83%|████████▎ | 79/95 [07:56<01:36,  6.03s/it] 84%|████████▍ | 80/95 [08:02<01:30,  6.02s/it]                                                84%|████████▍ | 80/95 [08:02<01:30,  6.02s/it] 85%|████████▌ | 81/95 [08:08<01:24,  6.01s/it] 86%|████████▋ | 82/95 [08:14<01:18,  6.03s/it] 87%|████████▋ | 83/95 [08:21<01:12,  6.04s/it] 88%|████████▊ | 84/95 [08:26<01:06,  6.02s/it] 89%|████████▉ | 85/95 [08:32<01:00,  6.00s/it] 91%|█████████ | 86/95 [08:38<00:54,  6.00s/it] 92%|█████████▏| 87/95 [08:45<00:48,  6.02s/it] 93%|█████████▎| 88/95 [08:51<00:42,  6.02s/it] 94%|█████████▎| 89/95 [08:57<00:36,  6.01s/it] 95%|█████████▍| 90/95 [09:03<00:30,  6.00s/it]                                                95%|█████████▍| 90/95 [09:03<00:30,  6.00s/it] 96%|█████████▌| 91/95 [09:09<00:24,  6.04s/it] 97%|█████████▋| 92/95 [09:15<00:18,  6.02s/it] 98%|█████████▊| 93/95 [09:21<00:12,  6.01s/it] 99%|█████████▉| 94/95 [09:27<00:05,  5.99s/it]100%|██████████| 95/95 [09:29<00:00,  5.08s/it]Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.
Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
{'loss': 2.4329, 'grad_norm': 3.0635297298431396, 'learning_rate': 0.00045263157894736845, 'epoch': 0.11}
{'loss': 1.2488, 'grad_norm': 2.0999507904052734, 'learning_rate': 0.0004, 'epoch': 0.21}
{'loss': 0.7475, 'grad_norm': 1.5874824523925781, 'learning_rate': 0.0003473684210526316, 'epoch': 0.32}
{'loss': 0.6684, 'grad_norm': 1.5329248905181885, 'learning_rate': 0.0003, 'epoch': 0.42}
{'loss': 0.7034, 'grad_norm': 1.8055942058563232, 'learning_rate': 0.0002473684210526316, 'epoch': 0.53}
{'loss': 0.6032, 'grad_norm': 2.0180857181549072, 'learning_rate': 0.00019473684210526317, 'epoch': 0.63}
{'loss': 0.5902, 'grad_norm': 1.4976412057876587, 'learning_rate': 0.00014210526315789474, 'epoch': 0.74}
{'loss': 0.5596, 'grad_norm': 1.475009799003601, 'learning_rate': 8.947368421052632e-05, 'epoch': 0.85}
{'loss': 0.5615, 'grad_norm': 1.3335825204849243, 'learning_rate': 3.6842105263157895e-05, 'epoch': 0.95}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:01<00:16,  1.37it/s][A
 12%|█▏        | 3/25 [00:02<00:22,  1.02s/it][A
 16%|█▌        | 4/25 [00:04<00:25,  1.19s/it][A
 20%|██        | 5/25 [00:05<00:25,  1.29s/it][A
 24%|██▍       | 6/25 [00:07<00:26,  1.38s/it][A
 28%|██▊       | 7/25 [00:08<00:25,  1.40s/it][A
 32%|███▏      | 8/25 [00:10<00:23,  1.40s/it][A
 36%|███▌      | 9/25 [00:11<00:22,  1.42s/it][A
 40%|████      | 10/25 [00:13<00:21,  1.42s/it][A
 44%|████▍     | 11/25 [00:14<00:20,  1.46s/it][A
 48%|████▊     | 12/25 [00:16<00:19,  1.47s/it][A
 52%|█████▏    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|█████▌    | 14/25 [00:19<00:16,  1.47s/it][A
 60%|██████    | 15/25 [00:20<00:14,  1.49s/it][A
 64%|██████▍   | 16/25 [00:22<00:13,  1.53s/it][A
 68%|██████▊   | 17/25 [00:23<00:12,  1.52s/it][A
 72%|███████▏  | 18/25 [00:25<00:10,  1.51s/it][A
 76%|███████▌  | 19/25 [00:26<00:09,  1.51s/it][A
 80%|████████  | 20/25 [00:28<00:07,  1.48s/it][A
 84%|████████▍ | 21/25 [00:29<00:06,  1.53s/it][A
 88%|████████▊ | 22/25 [00:31<00:04,  1.54s/it][A
 92%|█████████▏| 23/25 [00:32<00:03,  1.51s/it][A
 96%|█████████▌| 24/25 [00:34<00:01,  1.48s/it][A
100%|██████████| 25/25 [00:35<00:00,  1.28s/it][A                                               
                                               [A100%|██████████| 95/95 [10:10<00:00,  5.08s/it]
100%|██████████| 25/25 [00:38<00:00,  1.28s/it][A
                                               [A                                               100%|██████████| 95/95 [10:10<00:00,  5.08s/it]100%|██████████| 95/95 [10:10<00:00,  6.43s/it]
{'eval_loss': 0.5008545517921448, 'eval_wer': 21.15494568324757, 'eval_runtime': 40.5816, 'eval_samples_per_second': 4.904, 'eval_steps_per_second': 0.616, 'epoch': 1.0}
{'train_runtime': 610.5687, 'train_samples_per_second': 5.575, 'train_steps_per_second': 0.156, 'train_loss': 0.8814235637062474, 'epoch': 1.0}
Training complete.
Skipping all weight saves (--skip_save).
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:01<00:16,  1.37it/s] 12%|█▏        | 3/25 [00:02<00:22,  1.02s/it] 16%|█▌        | 4/25 [00:04<00:25,  1.19s/it] 20%|██        | 5/25 [00:05<00:25,  1.29s/it] 24%|██▍       | 6/25 [00:07<00:26,  1.38s/it] 28%|██▊       | 7/25 [00:08<00:25,  1.40s/it] 32%|███▏      | 8/25 [00:10<00:23,  1.41s/it] 36%|███▌      | 9/25 [00:11<00:22,  1.43s/it] 40%|████      | 10/25 [00:13<00:21,  1.43s/it] 44%|████▍     | 11/25 [00:14<00:20,  1.47s/it] 48%|████▊     | 12/25 [00:16<00:19,  1.47s/it] 52%|█████▏    | 13/25 [00:17<00:17,  1.47s/it] 56%|█████▌    | 14/25 [00:19<00:16,  1.47s/it] 60%|██████    | 15/25 [00:20<00:14,  1.48s/it] 64%|██████▍   | 16/25 [00:22<00:13,  1.52s/it] 68%|██████▊   | 17/25 [00:23<00:12,  1.52s/it] 72%|███████▏  | 18/25 [00:25<00:10,  1.52s/it] 76%|███████▌  | 19/25 [00:26<00:09,  1.52s/it] 80%|████████  | 20/25 [00:28<00:07,  1.49s/it] 84%|████████▍ | 21/25 [00:29<00:06,  1.54s/it] 88%|████████▊ | 22/25 [00:31<00:04,  1.55s/it] 92%|█████████▏| 23/25 [00:32<00:03,  1.53s/it] 96%|█████████▌| 24/25 [00:34<00:01,  1.49s/it]100%|██████████| 25/25 [00:35<00:00,  1.29s/it]100%|██████████| 25/25 [00:38<00:00,  1.54s/it]
[sweep] Metrics written to: /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_033.csv
