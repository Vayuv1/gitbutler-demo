CMD: python /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py --model_name openai/whisper-large-v3-turbo --dataset_part base --train_fraction 0.25 --validation_samples 200 --epochs 2 --language en --task transcribe --per_device_train_batch_size 6 --gradient_accumulation_steps 6 --learning_rate 0.001 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --seed 42 --num_proc 1 --eval_strategy epoch --eval_steps 100 --run_stage coarse --run_id coarse_031 --skip_save --metrics_csv /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_031.csv
Using the latest cached version of the module from /home/pandeys2/.cache/huggingface/modules/datasets_modules/datasets/HF-SaLAI--salai_atc0/6a6a809cccd83aaa7dae50203e4c7f7fc6313a701a3deebe3dfca35a211f125c (last modified on Wed Aug  6 19:14:44 2025) since it couldn't be found locally at HF-SaLAI/salai_atc0, or remotely on the Hugging Face Hub.
/home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py:326: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
Using device: cuda
---- PATH DEBUG ----
CWD:            /home/pandeys2/Workspace/salai
__file__:       /home/pandeys2/Workspace/salai/asr_finetune/atc0py_bc_whisper_finetune_input_params_sweep.py
script_dir:     /home/pandeys2/Workspace/salai/asr_finetune
repo_root:      /home/pandeys2/Workspace/salai
finetuned_dir:  /home/pandeys2/Workspace/salai/finetuned_models
OUTPUT DIR:     /home/pandeys2/Workspace/salai/finetuned_models/whisper_lora_whisper-large-v3-turbo_base
--------------------
trainable params: 3,276,800 || all params: 812,154,880 || trainable%: 0.4035
  0%|          | 0/96 [00:00<?, ?it/s]/home/pandeys2/Workspace/salai/.venv/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  1%|          | 1/96 [00:07<11:21,  7.18s/it]  2%|▏         | 2/96 [00:13<10:29,  6.70s/it]  3%|▎         | 3/96 [00:19<10:08,  6.54s/it]  4%|▍         | 4/96 [00:26<09:56,  6.48s/it]  5%|▌         | 5/96 [00:32<09:45,  6.43s/it]  6%|▋         | 6/96 [00:38<09:35,  6.40s/it]  7%|▋         | 7/96 [00:45<09:27,  6.38s/it]  8%|▊         | 8/96 [00:51<09:20,  6.37s/it]  9%|▉         | 9/96 [00:57<09:12,  6.35s/it] 10%|█         | 10/96 [01:04<09:05,  6.34s/it]                                                10%|█         | 10/96 [01:04<09:05,  6.34s/it] 11%|█▏        | 11/96 [01:10<08:58,  6.34s/it] 12%|█▎        | 12/96 [01:16<08:52,  6.34s/it] 14%|█▎        | 13/96 [01:23<08:46,  6.35s/it] 15%|█▍        | 14/96 [01:29<08:40,  6.35s/it] 16%|█▌        | 15/96 [01:36<08:33,  6.35s/it] 17%|█▋        | 16/96 [01:42<08:27,  6.34s/it] 18%|█▊        | 17/96 [01:48<08:20,  6.34s/it] 19%|█▉        | 18/96 [01:55<08:14,  6.34s/it] 20%|█▉        | 19/96 [02:01<08:07,  6.33s/it] 21%|██        | 20/96 [02:07<08:00,  6.33s/it]                                                21%|██        | 20/96 [02:07<08:00,  6.33s/it] 22%|██▏       | 21/96 [02:13<07:54,  6.33s/it] 23%|██▎       | 22/96 [02:20<07:48,  6.33s/it] 24%|██▍       | 23/96 [02:26<07:41,  6.33s/it] 25%|██▌       | 24/96 [02:32<07:35,  6.32s/it] 26%|██▌       | 25/96 [02:39<07:29,  6.32s/it] 27%|██▋       | 26/96 [02:45<07:22,  6.32s/it] 28%|██▊       | 27/96 [02:51<07:16,  6.33s/it] 29%|██▉       | 28/96 [02:58<07:10,  6.33s/it] 30%|███       | 29/96 [03:04<07:06,  6.36s/it] 31%|███▏      | 30/96 [03:11<06:59,  6.36s/it]                                                31%|███▏      | 30/96 [03:11<06:59,  6.36s/it] 32%|███▏      | 31/96 [03:17<06:52,  6.34s/it] 33%|███▎      | 32/96 [03:23<06:45,  6.34s/it] 34%|███▍      | 33/96 [03:29<06:38,  6.33s/it] 35%|███▌      | 34/96 [03:36<06:32,  6.33s/it] 36%|███▋      | 35/96 [03:42<06:26,  6.34s/it] 38%|███▊      | 36/96 [03:48<06:19,  6.33s/it] 39%|███▊      | 37/96 [03:55<06:12,  6.32s/it] 40%|███▉      | 38/96 [04:01<06:06,  6.31s/it] 41%|████      | 39/96 [04:07<06:00,  6.32s/it] 42%|████▏     | 40/96 [04:14<05:54,  6.33s/it]                                                42%|████▏     | 40/96 [04:14<05:54,  6.33s/it] 43%|████▎     | 41/96 [04:20<05:48,  6.33s/it] 44%|████▍     | 42/96 [04:26<05:42,  6.33s/it] 45%|████▍     | 43/96 [04:33<05:35,  6.33s/it] 46%|████▌     | 44/96 [04:39<05:29,  6.33s/it] 47%|████▋     | 45/96 [04:45<05:22,  6.32s/it] 48%|████▊     | 46/96 [04:52<05:16,  6.32s/it] 49%|████▉     | 47/96 [04:58<05:09,  6.32s/it] 50%|█████     | 48/96 [04:59<03:50,  4.81s/it]Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.
Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
{'loss': 2.2247, 'grad_norm': 2.0793113708496094, 'learning_rate': 0.0009166666666666666, 'epoch': 0.21}
{'loss': 0.8802, 'grad_norm': 1.5461736917495728, 'learning_rate': 0.0008125000000000001, 'epoch': 0.42}
{'loss': 0.6814, 'grad_norm': 1.517439842224121, 'learning_rate': 0.0007083333333333334, 'epoch': 0.63}
{'loss': 0.6109, 'grad_norm': 1.3492192029953003, 'learning_rate': 0.0006041666666666666, 'epoch': 0.85}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:01<00:17,  1.29it/s][A
 12%|█▏        | 3/25 [00:03<00:23,  1.08s/it][A
 16%|█▌        | 4/25 [00:04<00:26,  1.26s/it][A
 20%|██        | 5/25 [00:06<00:27,  1.35s/it][A
 24%|██▍       | 6/25 [00:07<00:27,  1.44s/it][A
 28%|██▊       | 7/25 [00:09<00:26,  1.46s/it][A
 32%|███▏      | 8/25 [00:10<00:25,  1.47s/it][A
 36%|███▌      | 9/25 [00:12<00:23,  1.49s/it][A
 40%|████      | 10/25 [00:13<00:22,  1.49s/it][A
 44%|████▍     | 11/25 [00:15<00:21,  1.53s/it][A
 48%|████▊     | 12/25 [00:16<00:19,  1.53s/it][A
 52%|█████▏    | 13/25 [00:18<00:18,  1.54s/it][A
 56%|█████▌    | 14/25 [00:20<00:16,  1.53s/it][A
 60%|██████    | 15/25 [00:21<00:15,  1.55s/it][A
 64%|██████▍   | 16/25 [00:23<00:14,  1.60s/it][A
 68%|██████▊   | 17/25 [00:24<00:12,  1.58s/it][A
 72%|███████▏  | 18/25 [00:26<00:11,  1.58s/it][A
 76%|███████▌  | 19/25 [00:28<00:09,  1.58s/it][A
 80%|████████  | 20/25 [00:29<00:07,  1.56s/it][A
 84%|████████▍ | 21/25 [00:31<00:06,  1.60s/it][A
 88%|████████▊ | 22/25 [00:32<00:04,  1.61s/it][A
 92%|█████████▏| 23/25 [00:34<00:03,  1.59s/it][A
 96%|█████████▌| 24/25 [00:35<00:01,  1.54s/it][A
100%|██████████| 25/25 [00:36<00:00,  1.33s/it][A                                               
                                               [A 50%|█████     | 48/96 [05:42<03:50,  4.81s/it]
100%|██████████| 25/25 [00:40<00:00,  1.33s/it][A
                                               [A 51%|█████     | 49/96 [05:48<14:10, 18.09s/it] 52%|█████▏    | 50/96 [05:55<11:09, 14.55s/it]                                                52%|█████▏    | 50/96 [05:55<11:09, 14.55s/it] 53%|█████▎    | 51/96 [06:01<09:02, 12.07s/it] 54%|█████▍    | 52/96 [06:07<07:35, 10.34s/it] 55%|█████▌    | 53/96 [06:14<06:32,  9.12s/it] 56%|█████▋    | 54/96 [06:20<05:47,  8.27s/it] 57%|█████▋    | 55/96 [06:26<05:14,  7.67s/it] 58%|█████▊    | 56/96 [06:32<04:49,  7.25s/it] 59%|█████▉    | 57/96 [06:39<04:32,  6.98s/it] 60%|██████    | 58/96 [06:45<04:17,  6.77s/it] 61%|██████▏   | 59/96 [06:51<04:05,  6.63s/it] 62%|██████▎   | 60/96 [06:58<03:54,  6.52s/it]                                                62%|██████▎   | 60/96 [06:58<03:54,  6.52s/it] 64%|██████▎   | 61/96 [07:04<03:45,  6.45s/it] 65%|██████▍   | 62/96 [07:10<03:37,  6.40s/it] 66%|██████▌   | 63/96 [07:16<03:30,  6.37s/it] 67%|██████▋   | 64/96 [07:23<03:22,  6.34s/it] 68%|██████▊   | 65/96 [07:29<03:15,  6.32s/it] 69%|██████▉   | 66/96 [07:35<03:09,  6.31s/it] 70%|██████▉   | 67/96 [07:42<03:02,  6.29s/it] 71%|███████   | 68/96 [07:48<02:56,  6.30s/it] 72%|███████▏  | 69/96 [07:54<02:49,  6.29s/it] 73%|███████▎  | 70/96 [08:00<02:43,  6.29s/it]                                                73%|███████▎  | 70/96 [08:00<02:43,  6.29s/it] 74%|███████▍  | 71/96 [08:07<02:37,  6.29s/it] 75%|███████▌  | 72/96 [08:13<02:31,  6.29s/it] 76%|███████▌  | 73/96 [08:19<02:24,  6.29s/it] 77%|███████▋  | 74/96 [08:26<02:18,  6.29s/it] 78%|███████▊  | 75/96 [08:32<02:11,  6.28s/it] 79%|███████▉  | 76/96 [08:38<02:05,  6.28s/it] 80%|████████  | 77/96 [08:44<01:59,  6.28s/it] 81%|████████▏ | 78/96 [08:51<01:52,  6.27s/it] 82%|████████▏ | 79/96 [08:57<01:46,  6.28s/it] 83%|████████▎ | 80/96 [09:03<01:40,  6.27s/it]                                                83%|████████▎ | 80/96 [09:03<01:40,  6.27s/it] 84%|████████▍ | 81/96 [09:09<01:34,  6.27s/it] 85%|████████▌ | 82/96 [09:16<01:27,  6.28s/it] 86%|████████▋ | 83/96 [09:22<01:21,  6.28s/it] 88%|████████▊ | 84/96 [09:28<01:15,  6.29s/it] 89%|████████▊ | 85/96 [09:35<01:09,  6.29s/it] 90%|████████▉ | 86/96 [09:41<01:02,  6.29s/it] 91%|█████████ | 87/96 [09:47<00:56,  6.29s/it] 92%|█████████▏| 88/96 [09:53<00:50,  6.29s/it] 93%|█████████▎| 89/96 [10:00<00:43,  6.28s/it] 94%|█████████▍| 90/96 [10:06<00:37,  6.28s/it]                                                94%|█████████▍| 90/96 [10:06<00:37,  6.28s/it] 95%|█████████▍| 91/96 [10:12<00:31,  6.28s/it] 96%|█████████▌| 92/96 [10:19<00:25,  6.28s/it] 97%|█████████▋| 93/96 [10:25<00:18,  6.28s/it] 98%|█████████▊| 94/96 [10:31<00:12,  6.27s/it] 99%|█████████▉| 95/96 [10:37<00:06,  6.27s/it]100%|██████████| 96/96 [10:39<00:00,  4.77s/it]{'eval_loss': 0.5218133330345154, 'eval_wer': 21.555174385363067, 'eval_runtime': 42.2919, 'eval_samples_per_second': 4.705, 'eval_steps_per_second': 0.591, 'epoch': 1.0}
{'loss': 0.473, 'grad_norm': 0.9291409850120544, 'learning_rate': 0.0005, 'epoch': 1.04}
{'loss': 0.3481, 'grad_norm': 1.0290471315383911, 'learning_rate': 0.0003958333333333333, 'epoch': 1.25}
{'loss': 0.3336, 'grad_norm': 1.2056472301483154, 'learning_rate': 0.0002916666666666667, 'epoch': 1.46}
{'loss': 0.3206, 'grad_norm': 1.0416851043701172, 'learning_rate': 0.0001875, 'epoch': 1.68}
{'loss': 0.3622, 'grad_norm': 0.886171817779541, 'learning_rate': 8.333333333333333e-05, 'epoch': 1.89}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|▊         | 2/25 [00:01<00:17,  1.30it/s][A
 12%|█▏        | 3/25 [00:03<00:23,  1.07s/it][A
 16%|█▌        | 4/25 [00:04<00:26,  1.24s/it][A
 20%|██        | 5/25 [00:06<00:26,  1.34s/it][A
 24%|██▍       | 6/25 [00:07<00:27,  1.43s/it][A
 28%|██▊       | 7/25 [00:09<00:26,  1.46s/it][A
 32%|███▏      | 8/25 [00:10<00:25,  1.47s/it][A
 36%|███▌      | 9/25 [00:12<00:23,  1.50s/it][A
 40%|████      | 10/25 [00:13<00:22,  1.50s/it][A
 44%|████▍     | 11/25 [00:15<00:21,  1.53s/it][A
 48%|████▊     | 12/25 [00:16<00:19,  1.53s/it][A
 52%|█████▏    | 13/25 [00:18<00:18,  1.53s/it][A
 56%|█████▌    | 14/25 [00:19<00:16,  1.52s/it][A
 60%|██████    | 15/25 [00:21<00:15,  1.54s/it][A
 64%|██████▍   | 16/25 [00:23<00:14,  1.59s/it][A
 68%|██████▊   | 17/25 [00:24<00:12,  1.58s/it][A
 72%|███████▏  | 18/25 [00:26<00:11,  1.58s/it][A
 76%|███████▌  | 19/25 [00:27<00:09,  1.58s/it][A
 80%|████████  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|████████▍ | 21/25 [00:31<00:06,  1.60s/it][A
 88%|████████▊ | 22/25 [00:32<00:04,  1.60s/it][A
 92%|█████████▏| 23/25 [00:34<00:03,  1.58s/it][A
 96%|█████████▌| 24/25 [00:35<00:01,  1.54s/it][A
100%|██████████| 25/25 [00:36<00:00,  1.32s/it][A                                               
                                               [A100%|██████████| 96/96 [11:21<00:00,  4.77s/it]
100%|██████████| 25/25 [00:39<00:00,  1.32s/it][A
                                               [A                                               100%|██████████| 96/96 [11:21<00:00,  4.77s/it]100%|██████████| 96/96 [11:21<00:00,  7.10s/it]
{'eval_loss': 0.4401073157787323, 'eval_wer': 18.067467124070898, 'eval_runtime': 42.1399, 'eval_samples_per_second': 4.722, 'eval_steps_per_second': 0.593, 'epoch': 2.0}
{'train_runtime': 681.3313, 'train_samples_per_second': 4.996, 'train_steps_per_second': 0.141, 'train_loss': 0.667191623399655, 'epoch': 2.0}
Training complete.
Skipping all weight saves (--skip_save).
  0%|          | 0/25 [00:00<?, ?it/s]  8%|▊         | 2/25 [00:01<00:17,  1.29it/s] 12%|█▏        | 3/25 [00:03<00:23,  1.08s/it] 16%|█▌        | 4/25 [00:04<00:26,  1.25s/it] 20%|██        | 5/25 [00:06<00:26,  1.34s/it] 24%|██▍       | 6/25 [00:07<00:27,  1.43s/it] 28%|██▊       | 7/25 [00:09<00:26,  1.46s/it] 32%|███▏      | 8/25 [00:10<00:24,  1.47s/it] 36%|███▌      | 9/25 [00:12<00:23,  1.49s/it] 40%|████      | 10/25 [00:13<00:22,  1.49s/it] 44%|████▍     | 11/25 [00:15<00:21,  1.53s/it] 48%|████▊     | 12/25 [00:16<00:19,  1.53s/it] 52%|█████▏    | 13/25 [00:18<00:18,  1.54s/it] 56%|█████▌    | 14/25 [00:19<00:16,  1.53s/it] 60%|██████    | 15/25 [00:21<00:15,  1.55s/it] 64%|██████▍   | 16/25 [00:23<00:14,  1.59s/it] 68%|██████▊   | 17/25 [00:24<00:12,  1.58s/it] 72%|███████▏  | 18/25 [00:26<00:11,  1.57s/it] 76%|███████▌  | 19/25 [00:27<00:09,  1.58s/it] 80%|████████  | 20/25 [00:29<00:07,  1.55s/it] 84%|████████▍ | 21/25 [00:31<00:06,  1.60s/it] 88%|████████▊ | 22/25 [00:32<00:04,  1.61s/it] 92%|█████████▏| 23/25 [00:34<00:03,  1.59s/it] 96%|█████████▌| 24/25 [00:35<00:01,  1.54s/it]100%|██████████| 25/25 [00:36<00:00,  1.32s/it]100%|██████████| 25/25 [00:39<00:00,  1.60s/it]
[sweep] Metrics written to: /home/pandeys2/Workspace/salai/asr_finetune/sweep_runs/tmp_metrics/coarse_031.csv
